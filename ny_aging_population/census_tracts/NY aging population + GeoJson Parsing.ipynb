{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import folium\n",
    "import branca\n",
    "import math\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def add_to_map(my_map, location_path, names_path, info_path, colorscale, cap, threshold, features, pop_data):\n",
    "    \n",
    "    # importing locations, it also have age info but I want to proccess them with pandas using the csv\n",
    "    with open(location_path) as f:\n",
    "        block_geojson = json.load(f)\n",
    "    #print(block_geojson['features'])\n",
    "\n",
    "    # importing info about column names \n",
    "    with open(names_path) as f:\n",
    "        metadata = json.load(f)\n",
    "    #print(metadata)\n",
    "\n",
    "    # importing info about age in csv format\n",
    "    df = pd.read_csv(info_path)\n",
    "\n",
    "    # dropping error columns, useless for plotting\n",
    "    df = df.drop([col for col in df.columns if \"Error\" in col], axis=1)\n",
    "\n",
    "    # changing df column names to human readable format\n",
    "    # starting with columns that are inclueded in the df but not in metadata file as they already are in a human readble format\n",
    "    new_names = [\"geoid\", \"name\"]\n",
    "    shared_names = []\n",
    "    # iterating over column names\n",
    "    for key, key_dict in metadata[\"tables\"][\"B01001\"][\"columns\"].items():\n",
    "        # if len of string is <8 give these results -> \"Total:\", \"Male:\", \"Female:\" -> stripping \":\" from them\n",
    "        if(len(key_dict[\"name\"]) < 8):\n",
    "            new_names.append(key_dict[\"name\"].strip(\":\"))\n",
    "        # the rest of the columns have the same name for female and male columns e.g \"65 and 66 years\" for both columns\n",
    "        # these columns are ordered in metadata file as first all male columns and then all female columns\n",
    "        # so if in a iteration the name is new  -> add the name to new_names as \"male\" and to the shared_names without anything else\n",
    "        # and if the names is not new (it is already in shared_names) -> add the name to new_names as \"female\" \n",
    "        # this enables the distinction between male columns and females columns\n",
    "        elif(key_dict[\"name\"] not in shared_names):\n",
    "            new_names.append(key_dict[\"name\"] + \" male\")\n",
    "            shared_names.append(key_dict[\"name\"])\n",
    "        else:\n",
    "            new_names.append(key_dict[\"name\"] + \" female\")\n",
    "    df.columns = new_names\n",
    "\n",
    "    # adding +65 column and percentage over total pop of the block, and cap percentage of total block\n",
    "    df[\"65 and over\"] = df['65 and 66 years female'] + df['67 to 69 years female'] \\\n",
    "                        + df['70 to 74 years female'] + df['75 to 79 years female'] \\\n",
    "                        + df['80 to 84 years female'] + df['85 years and over female'] \\\n",
    "                        + df['65 and 66 years male'] + df['67 to 69 years male'] \\\n",
    "                        + df['70 to 74 years male'] + df['75 to 79 years male'] \\\n",
    "                        + df['80 to 84 years male'] + df['85 years and over male']\n",
    "    df[\"65 and over percentage\"] = df[\"65 and over\"] / df[\"Total\"]\n",
    "    \n",
    "    cap_percentage_func = lambda x: x if math.isnan(float(x)) or x<cap else cap\n",
    "    df[\"65 and over cap percentage\"] = df[\"65 and over percentage\"].apply(cap_percentage_func)  \n",
    "    \n",
    "    # checking nans (blocks without data) and replace them with None to comply with style function\n",
    "    #display(df.loc[np.isnan(df[\"65 and over percentage\"])])\n",
    "    df = df.where(pd.notnull(df), None)\n",
    "\n",
    "    # checking if both data sources have the same size\n",
    "    assert len(block_geojson['features']), len(df)\n",
    "    assert len(df), df[\"geoid\"].nunique()\n",
    "    \n",
    "    #adding data to compute stats\n",
    "    pop_data.extend(df[\"65 and over cap percentage\"].values)\n",
    "\n",
    "    # checking if min and max percentage values are feasible\n",
    "    #display(df[\"65 and over percentage\"].describe().to_frame())\n",
    "                  \n",
    "    # creating style function\n",
    "    def style_function(feature):\n",
    "        block_df = df.loc[df[\"geoid\"]==feature['properties'][\"geoid\"]]\n",
    "        pop_per = block_df.iloc[0,-1] # -2 -> percentage with cap!!\n",
    "        return {'fillOpacity': 0.8, \n",
    "                'weight': 0, \n",
    "                'fillColor': '#ffffff00' if pop_per is None or pop_per < threshold else colorscale(pop_per)\n",
    "        }\n",
    "    #print(style_function(block_geojson['features'][0]))\n",
    "\n",
    "    # adding info to map\n",
    "    for block in block_geojson['features']:\n",
    "        \n",
    "        # adding block with proper style\n",
    "        gj = folium.GeoJson(block, style_function=style_function)\n",
    "        gj.add_to(my_map)\n",
    "        \n",
    "        # adding block popup with corresponding name and rounded and formatted percentage\n",
    "        block_df = df.loc[df[\"geoid\"]==block['properties'][\"geoid\"]]\n",
    "        pop_per = block_df.iloc[0,-2] # -2 -> percentage without cap!!\n",
    "        if pop_per is not None:\n",
    "            pop_per = \"{}%\".format(round(pop_per*100,2))\n",
    "        text = \"{}: {}\".format(block['properties'][\"name\"], pop_per)\n",
    "        gj.add_child(folium.Popup(text))\n",
    "        gj.add_to(my_map)\n",
    "        \n",
    "        #adding blocks to global json\n",
    "        feature_block = block.copy()\n",
    "        feature_block['properties']['pop%_+65'] = block_df.iloc[0,-2]\n",
    "        features.append(feature_block)\n",
    "    \n",
    "    return features, pop_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_stats = {\n",
    "    \"count\": 2202.000000,\n",
    "    \"mean\": 0.143090,\n",
    "    \"std\": 0.071672,\n",
    "    \"min\": 0.000000,\n",
    "    \"25%\": 0.097801,\n",
    "    \"50%\": 0.132974,\n",
    "    \"75%\": 0.175784,\n",
    "    \"max\": 1.000000\n",
    "}\n",
    "\n",
    "# creating map (location is Central Park), array of files of different places, and cap for color scale \n",
    "my_map = folium.Map(location=[40.785091, -73.968285], zoom_start=10)\n",
    "data_path = \"ny_census_tract\"\n",
    "cap = data_stats[\"50%\"]\n",
    "threshold = data_stats[\"50%\"]\n",
    "colorscale = branca.colormap.linear.Purples_05.scale(0,cap)\n",
    "features = []\n",
    "pop_data = []\n",
    "\n",
    "# add blocks of each file using:\n",
    "# 1. location path (coordinates file, format: geoJSON)\n",
    "# 2. names path (human readable columns file, format: json)\n",
    "# 3. info path (age info file, format: csv)\n",
    "\n",
    "l_path = '{}_data/{}.geojson'.format(data_path, data_path)\n",
    "n_path = '{}_data/metadata.json'.format(data_path, data_path)\n",
    "i_path = '{}_data/{}.csv'.format(data_path, data_path)\n",
    "features, pop_data = add_to_map(my_map, l_path, n_path, i_path, colorscale, cap, threshold, features, pop_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting map\n",
    "my_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving final map\n",
    "my_map.save('map.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "branca.colormap.linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GeoJSON Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "help(folium.Map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(pop_data, dtype=np.float).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_map = my_map.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('map_JSON.json', 'w') as fp:\n",
    "    json.dump(my_map.to_json(), fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(l_path) as f:\n",
    "    b_geojson = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_geojson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_geoJSON = {\n",
    "   'type': 'FeatureCollection',\n",
    "   'crs': {'type': 'name',\n",
    "           'properties': {'name': 'urn:ogc:def:crs:OGC:1.3:CRS84'}},\n",
    "   'features': features,\n",
    "   'stats': data_stats\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_geoJSON[\"stats\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('proccessed_geoJSON.json', 'w') as fp:\n",
    "    json.dump(final_geoJSON, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('proccessed_geoJSON.json') as f:\n",
    "    block_geojson = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_geojson[\"features\"][0][\"properties\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
